---

title: "DAP II:Final Project"
author: "Genevieve Madigan, Summer Negahdar, Jenny Zhong"
date: "Fall 2024"
format: html

---
# workflow and team members
Genevieve Madigan: #write your github Id here: Madigan989
-responsibility: write up and data visualization
Summer Negahdar: Summer99D
-responsibility: creation of shiny app and data visualization
Jenny Zhong: #write your github ID here
-responsibility: data cleaning and preparation



## Introduction and prior articles




## Data Cleaning

To Jenny and Gena: 
things we need to do:
1. upload temp app,


# Load your CSV file
# Crime data: Merging crime data together and merging crime data with ZIP Code
1. Loading data together
```{python}
import pandas as pd
import geopandas as gpd
import pandas as pd
from shapely.geometry import Point
```

```{python}
crime2004 = pd.read_csv('Crimes2004.csv')
crime2005 = pd.read_csv('Crimes2005.csv')
crimes67 = pd.read_csv('Crimes20062007.csv')
crimes8910 = pd.read_csv('Crimes20080910.csv')
crimes1112 = pd.read_csv('Crimes20112012.csv')
crimes131415 = pd.read_csv('Crimes201320142015.csv')
```

2. Examining the columns of crime data 
```{python}
print("2004 Columns:", crime2004.columns)
print("2005 Columns:", crime2005.columns)
print("2006 Columns:", crimes67.columns)
```

3. Merging all datasets together
```{python}
totalcrimedata = pd.concat([crime2004, crime2005, crimes67, crimes8910, crimes1112, crimes131415])
``` 

4. Examining the merged dataset
```{python}
print(totalcrimedata.info())
```


Whether all years exist
```{python}
print(totalcrimedata['Year'].value_counts())
```

Summary statistics for numerical columns 
```{python}
print(totalcrimedata.describe())
```

```{python}
totalcrimedata.to_csv("totalcrimedata.csv", index=False)
```

Converting latitude and longitude to ZIP Codes
```{python}
len(totalcrimedata)
```

Load ZIP code shapefiles
```{python}
zip_shapes = gpd.read_file("/Users/jennyzhong/Documents/GitHub/final-Project-DAP-II/ZIP Code Shapefiles/tl_2015_us_zcta510.shp")
```

```{python}
zip_shapes = zip_shapes.to_crs("EPSG:4326")
print(zip_shapes.head())
```

crime geometry
```{python}
geometry = [Point(xy) for xy in zip(totalcrimedata['Longitude'], totalcrimedata['Latitude'])]
```

```{python}
crime_gdf = gpd.GeoDataFrame(totalcrimedata, geometry=geometry, crs="EPSG:4326") 
print(crime_gdf.head())
```

```{python}
crime_gdf['geometry'] = crime_gdf.geometry.buffer(0.01)
```

Merging two data sets
```{python}
matched_data = gpd.sjoin(crime_gdf, zip_shapes, how="left", predicate="intersects")

matched_data.to_csv("matched_data.csv", index=False)
```

clean data
```{python}
matched_data.drop(columns=['ID', 'District', 'Community Area', 'CLASSFP10', 'MTFCC10', 'FUNCSTAT10', 'ALAND10', 'AWATER10', 'FBI Code', 'Updated On', 'GEOID10'], inplace=True)
```

operate from CSV file
```{python}
matched_data = pd.read_csv("matched_data.csv")
print(matched_data.head())
```

Drop appropriate columns 
```{python}
matched_data.drop(columns=['ID', 'District', 'Community Area', 'CLASSFP10', 'MTFCC10', 'FUNCSTAT10', 'ALAND10', 'AWATER10', 'FBI Code', 'Updated On', 'GEOID10'], inplace=True)
print(matched_data.head())
```

```{python}
matched_data['Date'] = pd.to_datetime(matched_data['Date'], errors='coerce')
```

```{python}
matched_data['YearMonthDay'] = matched_data['Date'].dt.date
matched_data['Time'] = matched_data['Date'].dt.time
```

```{python}
matched_data.drop(columns=['Date', 'Time', 'GEOID10', 'CLASSFP10', 'MTFCC10', 'FUNCSTAT10', 'ALAND10', 'AWATER10', 'Updated On', 'FBI Code'], inplace=True)
matched_data.head(5)
```

```{python}
columns = matched_data.columns.tolist()
columns.remove('YearMonthDay')
columns.insert(columns.index('Case Number') + 1, 'YearMonthDay')
matched_data = matched_data[columns]
print(matched_data.columns)
```

```{python}
matched_data.to_csv("final_crime_data.csv", index=False)
```

# Merging weather data together and merging weather data with ZIP code 

Merging all datasets together
```{python}
weather2004 = pd.read_csv('AT2004.csv')
weather2005 = pd.read_csv('AT2005.csv')
weather2006 = pd.read_csv('AT2006.csv')
weather2007 = pd.read_csv('AT2007.csv')
weather2008 = pd.read_csv('AT2008.csv')
weather2009 = pd.read_csv('AT2009.csv')
weather2010 = pd.read_csv('AT2010.csv')
weather2011 = pd.read_csv('AT2011.csv')
weather2012 = pd.read_csv('AT2012.csv')
weather2013 = pd.read_csv('AT2013.csv')
weather2014 = pd.read_csv('AT2014.csv')
weather2015 = pd.read_csv('AT2015.csv')
```

```{python}
total_weather = pd.concat([
    weather2004, weather2005, weather2006, weather2007, weather2008, 
    weather2009, weather2010, weather2011, weather2012, weather2013, 
    weather2014, weather2015
], ignore_index=True)

total_weather_data.to_csv('merged_weather_data.csv', index=False)
```

```{python}
total_weather.head(20)
```

convert weather data to geodataframe
```{python}
geometry = [Point(xy) for xy in zip(total_weather['LONGITUDE'], total_weather['LATITUDE'])]

weather_gdf = gpd.GeoDataFrame(total_weather, geometry=geometry)

weather_gdf.set_crs("EPSG:4326", inplace=True)

weather_gdf['geometry'] = weather_gdf.geometry.buffer(0.01)
```

Load the ZIP Code Shapefile
```{python}
zip_shapefile = gpd.read_file('/Users/jennyzhong/Documents/GitHub/final-Project-DAP-II/ZIP_Code_Shapefiles/tl_2015_us_zcta510.shp')

zip_shapefile = zip_shapefile.to_crs("EPSG:4326")
```

Spatial join to match the zip codes
```{python}
weather_with_zip = gpd.sjoin(weather_gdf, zip_shapefile, how='left', predicate='intersects')

print(weather_with_zip.head())
```

drop irrelevant dataframes: 
```{python}
weather_with_zip.drop(["CLASSFP10", "MTFCC10", "FUNCSTAT10", "ALAND10", "AWATER10", "GEOID10"], axis=1, inplace=True)

print(weather_with_zip)
```

final csv file for weather 
```{python}
weather_with_zip.to_csv("final_weather_data.csv", index=False)
```

# Apply function to your data

# Save the updated dataframe to a new CSV




2. save the file as df and as csv file (in the data folder)
3. upload crime rate
4. clean crime df
5. save it as df and as csv (in data folder)
6. merge both dfs based on ????
7. make a scatterplot of crime rate and temperature
8. make a base map (shapely)
9. make a heated map using scatterplot and base map
10. save the final merged csv(in data folder)
11. shiny app
12. (extra credit): use NLP for finding crime-heat (it sohuld not be hard I'd say)



```{python}
##installing the necessary packages
import pandas as pd
import altair as alt
import numpy as np
import geopandas as gpd
import shapely
import shiny
#from shapely.geometry import Point
#import pgeocode
```



## Data experiment
```{python}

```

## Data Visualization
#merging the data

```{python}

final_crime_data = pd.read_csv(r'C:\Users\madig\Documents\Github\Year 2024-2025\final-Project-DAP-II\final_crime_data.csv')
final_weather_data = pd.read_csv(r'C:\Users\madig\Documents\Github\Year 2024-2025\final-Project-DAP-II\final_weather_data.csv')


```


```{python}
import pandas as pd


final_crime_data = pd.read_csv(r'C:\Users\madig\Documents\Github\Year 2024-2025\final-Project-DAP-II\final_crime_data.csv')

# Convert the 'YearMonthDay' column to datetime format
final_crime_data['DATE'] = pd.to_datetime(final_crime_data['YearMonthDay'])

# Filter for the years 2010 to 2015
filtered_crime_data = final_crime_data[
    (final_crime_data['DATE'].dt.year >= 2010) & (final_crime_data['DATE'].dt.year <= 2015)
]

# Display the filtered DataFrame
print(filtered_crime_data.head())

# Save the filtered dataset to a new file if needed
filtered_crime_data.to_csv('filtered_crime_data.csv', index=False)

```

```{python}
# Display the filtered DataFrame
print(filtered_crime_data.head())
```

```{python}

import pandas as pd

filtered_weather_data = pd.read_csv(r'C:\Users\madig\Documents\Github\Year 2024-2025\final-Project-DAP-II\Final project\short_weather_df.csv')

filtered_crime_data = pd.read_csv(r'C:\Users\madig\Documents\Github\Year 2024-2025\final-Project-DAP-II\Final project\filtered_crime_data.csv')

print(filtered_weather_data.head())

print(filtered_crime_data.head())


```


Merging 


```{python}


import pandas as pd

# Load the filtered datasets
filtered_weather_data = pd.read_csv(r'C:\Users\madig\Documents\Github\Year 2024-2025\final-Project-DAP-II\Final project\short_weather_df.csv')
filtered_crime_data = pd.read_csv(r'C:\Users\madig\Documents\Github\Year 2024-2025\final-Project-DAP-II\Final project\filtered_crime_data.csv')

# Ensure DATE columns are in datetime format
filtered_crime_data['DATE'] = pd.to_datetime(filtered_crime_data['DATE'])
filtered_weather_data['DATE'] = pd.to_datetime(filtered_weather_data['DATE'])

# Aggregate crime counts by date and ZIP code
crime_summary = filtered_crime_data.groupby(['DATE', 'ZCTA5CE10']).size().reset_index(name='Crime Count')

# Aggregate average temperature by date and ZIP code
weather_summary = filtered_weather_data.groupby(['DATE', 'ZCTA5CE10'])['TAVG'].mean().reset_index()

# Merge datasets on DATE and ZCTA5CE10
merged_data = pd.merge(
    crime_summary,
    weather_summary,
    on=['DATE', 'ZCTA5CE10'],
    how='inner'
)

# Select relevant columns and preview the merged dataset
print(merged_data.head())

# Optionally save the merged dataset
merged_data.to_csv(r'C:\Users\madig\Documents\Github\Year 2024-2025\final-Project-DAP-II\Final project\merged_data.csv', index=False)


```




Now that the data is filtered lets make the two charts


Scatterplot

```{python}

import pandas as pd
import matplotlib.pyplot as plt

# Load datasets
filtered_weather_data = pd.read_csv(r'C:\Users\madig\Documents\Github\Year 2024-2025\final-Project-DAP-II\Final project\short_weather_df.csv')
filtered_crime_data = pd.read_csv(r'C:\Users\madig\Documents\Github\Year 2024-2025\final-Project-DAP-II\Final project\filtered_crime_data.csv')

# Ensure DATE columns are in datetime format
filtered_crime_data['DATE'] = pd.to_datetime(filtered_crime_data['DATE'])
filtered_weather_data['DATE'] = pd.to_datetime(filtered_weather_data['DATE'])

# Aggregate crime data by DATE
crime_summary = filtered_crime_data.groupby('DATE').size().reset_index(name='Crime Count')

# Aggregate weather data by DATE
weather_summary = filtered_weather_data.groupby('DATE')['TAVG'].mean().reset_index()

# Plot scatterplot
plt.scatter(weather_summary['TAVG'], crime_summary['Crime Count'], alpha=0.5)
plt.title('Crime Count vs. Average Temperature')
plt.xlabel('Average Temperature (TAVG)')
plt.ylabel('Crime Count')
plt.grid(True)
plt.show()


```

Heatmap

```{python}
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load datasets
filtered_weather_data = pd.read_csv(r'C:\Users\madig\Documents\Github\Year 2024-2025\final-Project-DAP-II\Final project\short_weather_df.csv')
filtered_crime_data = pd.read_csv(r'C:\Users\madig\Documents\Github\Year 2024-2025\final-Project-DAP-II\Final project\filtered_crime_data.csv')

# Ensure DATE columns are in datetime format
filtered_crime_data['DATE'] = pd.to_datetime(filtered_crime_data['DATE'])
filtered_weather_data['DATE'] = pd.to_datetime(filtered_weather_data['DATE'])

# Extract month from the DATE column
filtered_crime_data['Month'] = filtered_crime_data['DATE'].dt.month
filtered_weather_data['Month'] = filtered_weather_data['DATE'].dt.month

# Handle missing values in ZCTA5CE10
filtered_crime_data = filtered_crime_data.dropna(subset=['ZCTA5CE10'])
filtered_weather_data = filtered_weather_data.dropna(subset=['ZCTA5CE10'])

# Convert ZCTA5CE10 to integers
filtered_crime_data['ZCTA5CE10'] = filtered_crime_data['ZCTA5CE10'].astype(int)
filtered_weather_data['ZCTA5CE10'] = filtered_weather_data['ZCTA5CE10'].astype(int)

# Group ZIP codes into 10 categories based on quantiles
zip_groups = pd.qcut(filtered_crime_data['ZCTA5CE10'], 10, labels=False)
filtered_crime_data['ZIP Group'] = zip_groups
filtered_weather_data['ZIP Group'] = pd.cut(
    filtered_weather_data['ZCTA5CE10'],
    bins=pd.qcut(filtered_crime_data['ZCTA5CE10'], 10, retbins=True)[1],
    labels=False,
    include_lowest=True
)

# Aggregate crime data by Month and ZIP group
crime_summary = filtered_crime_data.groupby(['Month', 'ZIP Group']).size().reset_index(name='Crime Count')

# Aggregate weather data by Month and ZIP group
weather_summary = filtered_weather_data.groupby(['Month', 'ZIP Group'])['TAVG'].mean().reset_index()

# Merge datasets on Month and ZIP group
merged_data = pd.merge(crime_summary, weather_summary, on=['Month', 'ZIP Group'], how='outer')

# Fill missing data
merged_data['Crime Count'].fillna(0, inplace=True)
merged_data['TAVG'].fillna(0, inplace=True)

# Pivot data for the heatmap
heatmap_data = merged_data.pivot_table(
    index='ZIP Group', 
    columns='Month', 
    values='TAVG', 
    aggfunc='mean'
)

# Pivot data for annotations
annotation_data = merged_data.pivot_table(
    index='ZIP Group', 
    columns='Month', 
    values='Crime Count', 
    aggfunc='sum'
)

# Align shapes of both dataframes
heatmap_data, annotation_data = heatmap_data.align(annotation_data, join='inner', axis=1)

# Create the heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(
    heatmap_data, 
    annot=annotation_data, 
    fmt='.0f', 
    cmap='coolwarm', 
    cbar_kws={'label': 'Average Temperature (TAVG)'}
)

# Add labels and title
plt.title('Heatmap of Temperature by Month and ZIP Code Groups\nCrime Count as Annotations', fontsize=14)
plt.xlabel('Month')
plt.ylabel('ZIP Code Group')
plt.tight_layout()
plt.show()

```

## Shiny App
```{python}



# Ensure DATE columns are in datetime format
filtered_crime_data['DATE'] = pd.to_datetime(filtered_crime_data['DATE'])
filtered_weather_data['DATE'] = pd.to_datetime(filtered_weather_data['DATE'])

# Merge datasets on DATE and ZCTA5CE10
merged_data = pd.merge(
    filtered_crime_data,
    filtered_weather_data[['DATE', 'ZCTA5CE10', 'TAVG']],
    on=['DATE', 'ZCTA5CE10'],
    how='inner'
)

# Create temperature bins (0, 15, 30, 45, 60, 75, 90)
temp_bins = [0, 15, 30, 45, 60, 75, 90]
temp_labels = [f'{temp_bins[i]}-{temp_bins[i+1]-1}°F' for i in range(len(temp_bins) - 1)]
merged_data['Temp Range'] = pd.cut(merged_data['TAVG'], bins=temp_bins, labels=temp_labels, include_lowest=True)

# Group by temperature range and crime type
crime_by_temp = merged_data.groupby(['Temp Range', 'Primary Type']).size().reset_index(name='Crime Count')

# Pivot data to prepare for stacked bar chart
pivot_data = crime_by_temp.pivot(index='Temp Range', columns='Primary Type', values='Crime Count').fillna(0)

# Plot the stacked bar chart
pivot_data.plot(kind='bar', stacked=True, figsize=(12, 8))

# Customize the chart
plt.title('Crime Types by Temperature Range', fontsize=16)
plt.xlabel('Temperature Range (°F)', fontsize=12)
plt.ylabel('Crime Count', fontsize=12)
plt.legend(title='Crime Types', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()

# Show the plot
plt.show()


```


```{python}


# Ensure DATE columns are in datetime format
filtered_crime_data['DATE'] = pd.to_datetime(filtered_crime_data['DATE'])
filtered_weather_data['DATE'] = pd.to_datetime(filtered_weather_data['DATE'])

# Merge datasets on DATE and ZCTA5CE10
merged_data = pd.merge(
    filtered_crime_data,
    filtered_weather_data[['DATE', 'ZCTA5CE10', 'TAVG']],
    on=['DATE', 'ZCTA5CE10'],
    how='inner'
)

# Create temperature bins (0-10, 10-20, ..., 70-80)
temp_bins = [0, 10, 20, 30, 40, 50, 60, 70, 80]
temp_labels = [f'{temp_bins[i]}-{temp_bins[i+1]-1}°F' for i in range(len(temp_bins) - 1)]
merged_data['Temp Range'] = pd.cut(merged_data['TAVG'], bins=temp_bins, labels=temp_labels, include_lowest=True)

# Group by temperature range and crime type
crime_by_temp = merged_data.groupby(['Temp Range', 'Primary Type']).size().reset_index(name='Crime Count')

# Pivot data to prepare for stacked bar chart
pivot_data = crime_by_temp.pivot(index='Temp Range', columns='Primary Type', values='Crime Count').fillna(0)

# Plot the stacked bar chart
pivot_data.plot(kind='bar', stacked=True, figsize=(12, 8))

# Customize the chart
plt.title('Crime Types by Temperature Range', fontsize=16)
plt.xlabel('Temperature Range (°F)', fontsize=12)
plt.ylabel('Crime Count', fontsize=12)
plt.legend(title='Crime Types', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()

# Show the plot
plt.show()
 
```



```{python}

# Load datasets
weather_short = pd.read_csv(r'C:\Users\madig\Documents\Github\Year 2024-2025\final-Project-DAP-II\Final project\short_weather_df.csv')
crime_short = pd.read_csv(r'C:\Users\madig\Documents\Github\Year 2024-2025\final-Project-DAP-II\Final project\filtered_crime_data.csv')



crime_short['date'] = pd.to_datetime(crime_short['DATE'])
weather_short['date'] = pd.to_datetime(weather_short['DATE'])

# Group by date and ZIP code
crime_counts_per_zip = crime_short.groupby(['date', 'ZCTA5CE10']).size().reset_index(name='total_crimes')
print(crime_counts_per_zip.head())

# Merge with weather data
merged_df = pd.merge(crime_counts_per_zip, weather_short, on='date', how='right')
print(merged_df.head())



```


```{python}

#Making a function to group crime types

filtered_crime_data = pd.read_csv(r'C:\Users\madig\Documents\Github\Year 2024-2025\final-Project-DAP-II\Final project\filtered_crime_data.csv')
unique_primary_types = filtered_crime_data['Primary Type'].unique()

def categorize_crime(crime_type):
    if crime_type in ['BATTERY', 'ASSAULT', 'ROBBERY', 'SEX OFFENSE', 
                      'CRIM SEXUAL ASSAULT', 'CRIMINAL SEXUAL ASSAULT', 
                      'HOMICIDE', 'KIDNAPPING', 'STALKING', 'INTIMIDATION']:
        return 'Violent Crimes'
    elif crime_type in ['MOTOR VEHICLE THEFT', 'THEFT', 'BURGLARY', 
                        'CRIMINAL DAMAGE', 'ARSON', 'CRIMINAL TRESPASS']:
        return 'Property Crimes'
    elif crime_type in ['WEAPONS VIOLATION', 'PUBLIC PEACE VIOLATION', 
                        'LIQUOR LAW VIOLATION', 'OBSCENITY', 
                        'PUBLIC INDECENCY', 'CONCEALED CARRY LICENSE VIOLATION']:
        return 'Public Order and Regulatory Violations'
    else:
        return 'Other Offenses'

# Apply it to make a new column
filtered_crime_data['Crime Type Group'] = filtered_crime_data['Primary Type'].apply(categorize_crime)

# If you want to heck the result
#print(filtered_crime_data[['Primary Type', 'Crime Type Group']].head())

columns_to_drop = [
    'YearMonthDay', 'Block', 'IUCR', 'Primary Type', 'Description',
    'Location Description', 'Arrest', 'Domestic', 'Beat', 'Ward',
    'FBI Code', 'X Coordinate', 'Y Coordinate', 'Year', 'Location',
    'ID', 'District', 'Community Area', 'index_right', 'INTPTLAT10', 
    'INTPTLON10'
]

filtered_crime_data = filtered_crime_data.drop(columns=columns_to_drop)

#Making the zip code an int
filtered_crime_data = filtered_crime_data.dropna(subset=['ZCTA5CE10'])
filtered_crime_data['ZCTA5CE10'] = filtered_crime_data['ZCTA5CE10'].astype(int)

#Dataframe preview
print(filtered_crime_data.head())
```